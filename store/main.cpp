#include <fstream>
#include <vector>
#include <chrono>
#include <memory>
#include <string>

// COM
#include <cstdio>
#include <unistd.h>
#include "serial.h"

#include <inference_engine.hpp>
#include <format_reader_ptr.h>

#include <samples/common.hpp>
#include <samples/slog.hpp>
#include <samples/args_helper.hpp>

#include "classification_sample.h"

#include "opencv2/opencv.hpp"
#include "mv_init.h"

//using namespace cv;
using namespace InferenceEngine;

bool ParseAndCheckCommandLine(int argc, char *argv[]) {
	// ---------------------------Parsing and validation of input args--------------------------------------
	gflags::ParseCommandLineNonHelpFlags(&argc, &argv, true);
	if (FLAGS_h) {
		showUsage();
		return false;
	}
	slog::info << "Parsing input parameters" << slog::endl;

	if (FLAGS_m.empty()) {
		throw std::logic_error("Parameter -m is not set");
	}

	return true;
}

typedef std::chrono::high_resolution_clock Time;
typedef std::chrono::duration<double, std::ratio<1, 1000>> ms;
typedef std::chrono::duration<float> fsec;
/**
* @brief The entry point the Inference Engine sample application
* @file classification_sample/main.cpp
* @example classification_sample/main.cpp
*/
int main(int argc, char *argv[]) {
	try {
		slog::info << "InferenceEngine: " << GetInferenceEngineVersion() << slog::endl;
        // ------------------------------ Parsing and validation of input args ---------------------------------
        if (!ParseAndCheckCommandLine(argc, argv)) {
            return 0;
        }

		cv::Mat srcImg;

		//srcImg = cv::imread("/home/action/code/caffe/data_two/daxiang.jpg");
		// --------------------------- 1. Load Plugin for inference engine -------------------------------------
		slog::info << "Loading plugin" << slog::endl;
		InferencePlugin plugin = PluginDispatcher({ FLAGS_pp, "/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64" , "" }).getPluginByDevice(FLAGS_d);
		//plugin.AddExtension(std::make_shared<Extensions::Cpu::CpuExtensions>());
		/** Printing plugin version **/
		printPluginVersion(plugin, std::cout);

		// --------------------------- 2. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
		std::string binFileName = fileNameNoExt(FLAGS_m) + ".bin";
        slog::info << "Loading network files:"
                "\n\t" << FLAGS_m <<
                "\n\t" << binFileName <<
        slog::endl;

		CNNNetReader networkReader;
		/** Reading network model **/
		networkReader.ReadNetwork(FLAGS_m);

		/** Extracting model name and loading weights **/
		networkReader.ReadWeights(binFileName);
		CNNNetwork network = networkReader.getNetwork();
		// --------------------------- 3. Configure input & output ---------------------------------------------

	   // --------------------------- Prepare input blobs -----------------------------------------------------
		slog::info << "Preparing input blobs" << slog::endl;

		/** Taking information about all topology inputs **/
		InputsDataMap inputInfo = network.getInputsInfo();
		if (inputInfo.size() != 1) throw std::logic_error("Sample supports topologies only with 1 input");

		auto inputInfoItem = *inputInfo.begin();

		/** Specifying the precision and layout of input data provided by the user.
		 * This should be called before load of the network to the plugin **/
		inputInfoItem.second->setPrecision(Precision::U8);
		inputInfoItem.second->setLayout(Layout::NCHW);
		int width = inputInfoItem.second->getTensorDesc().getDims()[3];
		int height = inputInfoItem.second->getTensorDesc().getDims()[2];

		/** Setting batch size using image count **/
		network.setBatchSize(1);
		size_t batchSize = network.getBatchSize();
		slog::info << "Batch size is " << std::to_string(batchSize) << slog::endl;
		std::shared_ptr<unsigned char> imagesData;
		// ------------------------------ Prepare output blobs -------------------------------------------------
		slog::info << "Preparing output blobs" << slog::endl;

		OutputsDataMap outputInfo(network.getOutputsInfo());
		// BlobMap outputBlobs;
		std::string firstOutputName;

		for (auto & item : outputInfo) {
			if (firstOutputName.empty()) {
				firstOutputName = item.first;
			}
			DataPtr outputData = item.second;
			if (!outputData) {
				throw std::logic_error("output data pointer is not valid");
			}

			item.second->setPrecision(Precision::FP32);
		}

		const SizeVector outputDims = outputInfo.begin()->second->getDims();

		bool outputCorrect = false;
		if (outputDims.size() == 2 /* NC */) {
			outputCorrect = true;
		}
		else if (outputDims.size() == 4 /* NCHW */) {
			/* H = W = 1 */
			if (outputDims[2] == 1 && outputDims[3] == 1) outputCorrect = true;
		}

		if (!outputCorrect) {
			throw std::logic_error("Incorrect output dimensions for classification model");
		}
		// -----------------------------------------------------------------------------------------------------

		// --------------------------- 4. Loading model to the plugin ------------------------------------------
		slog::info << "Loading model to the plugin" << slog::endl;

		ExecutableNetwork executable_network = plugin.LoadNetwork(network, {});
		inputInfoItem.second = {};
		outputInfo = {};
		network = {};
		networkReader = {};
		// -----------------------------------------------------------------------------------------------------

		// --------------------------- 5. Create infer request -------------------------------------------------
		InferRequest infer_request = executable_network.CreateInferRequest();
		// -----------------------------------------------------------------------------------------------------

		
		// 相机初始化
		MvInit camera;
		
		// 串口初始化
		serial::Serial my_serial(FLAGS_com, 115200, serial::Timeout::simpleTimeout(2));
		if(my_serial.isOpen())
		{
			slog::info << "serial port" << "initialize ok" << slog::endl;
		}else{
			slog::err << "serial port initialize err,please check your COM" << slog::endl;
			return -1;
		}
		// 创建自适应混合高斯背景建模的背景减除法
		Ptr<BackgroundSubtractorMOG2> bgsubtractor = createBackgroundSubtractorMOG2();
		bgsubtractor->setVarThreshold(10);

		// 读取图像测试
		cv::VideoCapture videoSrc("/home/action/Videos/1.avi");
		
		while (!camera.m_bExit)
		{
			// start time count
			auto t0 = Time::now();
			//srcImg = camera.getImage();
			videoSrc >> srcImg;
			if (srcImg.empty())
			{
				slog::err << "didn't get image" << slog::endl;
				cv::destroyWindow("src");
				return -1;
			}
			cv::imshow("src", srcImg);
			cv::Mat resized(srcImg);
			//if (srcImg.empty()) throw std::logic_error("No suitable images were found");
			cv::resize(srcImg, resized, cv::Size(width, height));
			// --------------------------- 6. bsg --------------------------------------------------------
			Mat bgmask;Mat temp;
			bgsubtractor->apply(resized,bgmask,0.05);
			threshold(bgmask,temp,5,255,THRESH_BINARY);
			//imshow("thres",temp);
			medianBlur(temp,temp,7);
			//int a = bSums(temp);
			int whitePointNum = countNonZero(temp);
			if (FLAGS_dg)
			{
				imshow("bmk",bgmask);
				imshow("mdblur",temp);
				std::cout << whitePointNum <<std::endl;
			}else{

			}
			if(whitePointNum > 3000)
			{
				cv::waitKey(30);
				continue;
			}
			size_t size = resized.size().width * resized.size().height * resized.channels();

			imagesData.reset(new unsigned char[size], std::default_delete<unsigned char[]>());
			for (size_t id = 0; id < size; ++id) {
				imagesData.get()[id] = resized.data[id];
			}
			if (imagesData.get() == nullptr)
			{
				throw std::logic_error("Valid input images were not found!");
			}
			// --------------------------- 6. Prepare input --------------------------------------------------------
				/** Iterate over all the input blobs **/
			for (const auto & item : inputInfo) {
				/** Creating input blob **/
				Blob::Ptr input = infer_request.GetBlob(item.first);

				/** Filling input tensor with images. First b channel, then g and r channels **/
				size_t num_channels = input->getTensorDesc().getDims()[1];

				size_t image_size = input->getTensorDesc().getDims()[2] * input->getTensorDesc().getDims()[3];

				auto data = input->buffer().as<PrecisionTrait<Precision::U8>::value_type*>();
				/** Iterate over all pixel in image (b,g,r) **/
				for (size_t pid = 0; pid < image_size; pid++) {
					/** Iterate over all channels **/
					for (size_t ch = 0; ch < num_channels; ++ch) {
						/** [images stride + channels stride + pixel id ] all in bytes            **/
						//将imagesData中的数据分为b:0-9999,g:10000-19999,r:20000-29999.
						data[ch * image_size + pid] = imagesData.get()[pid*num_channels + ch];
					}
				}
			}
			// inputInfo = {};
			// -----------------------------------------------------------------------------------------------------
			// --------------------------- 7. Do inference ---------------------------------------------------------
			/** Start inference & calc performance **/
			infer_request.Infer();

			// -----------------------------------------------------------------------------------------------------
					// --------------------------- 8. Process output -------------------------------------------------------
			const Blob::Ptr output_blob = infer_request.GetBlob(firstOutputName);
			auto output_data = output_blob->buffer().as<PrecisionTrait<Precision::FP32>::value_type*>();

			/** Validating -nt value **/
			const int resultsCnt = output_blob->size() / batchSize;
			FLAGS_nt = resultsCnt;

			/** This vector stores id's of top N results **/
			std::vector<unsigned> results;
			TopResults(FLAGS_nt, *output_blob, results);

			/** Print the result iterating over each batch **/
			//for (size_t id = 0, cnt = 0; cnt < FLAGS_nt; ++cnt, ++id) {
			//	std::cout.precision(7);
			//	/** Getting probability for resulting class **/
			//	const auto result = output_data[results[id]];
			//	std::cout << std::left << std::fixed << results[id] << " " << result;
			//	std::cout << " label #" << results[id] << std::endl;
			//}

			// -----------------------------------------------------------------------------------------------------

			/** Show performance results **/
			if (FLAGS_pc) {
				printPerformanceCounts(infer_request, std::cout);
			}
			double total = 0;
			auto t1 = Time::now();
			fsec fs = t1 - t0;
			ms d = std::chrono::duration_cast<ms>(fs);
			total = d.count();

			std::string sendbuf = "CV" + std::to_string(results[0]) + "\r\n";
			if (FLAGS_dg){
				std::cout <<"class:" << results[0];
				std::cout << std::endl;
				std::cout << "total inference time: " << total << std::endl;
				std::cout << "Throughput: " << 1000 * static_cast<double>(FLAGS_ni) * batchSize / total << " FPS" << std::endl;
				std::cout << std::endl;
			}else{			
				my_serial.write(sendbuf);
				std::string getComCmd = my_serial.read(4);
				if(!getComCmd.compare("exit"))
				{
					camera.m_bExit = TRUE;
					break;
				}
			}
	
			// waitKey不是精确延时
			int c = cv::waitKey(30);
			if (c == 'q' || c == 'Q' || (c & 255) == 27)
			{
				camera.m_bExit = TRUE;
				break;
			}		
		}
		//等待线程终止，同步释放资源。
		if (pthread_join(camera.id, NULL))
		{
			printf("error join thread.");
			abort();
		}
		std::cout << "release source finish!" << std::endl;
	}
	catch (const std::exception& error) {
		slog::err << "" << error.what() << slog::endl;
		return 1;
	}
	catch (...) {
		slog::err << "Unknown/internal exception happened." << slog::endl;
		return 1;
	}

	slog::info << "Execution successful" << slog::endl;
	return 0;
}