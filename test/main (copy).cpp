// Copyright (C) 2018 Intel Corporation
// SPDX-License-Identifier: Apache-2.0
//

#include <gflags/gflags.h>
#include <functional>
#include <iostream>
#include <fstream>
#include <random>
#include <string>
#include <memory>
#include <vector>
#include <time.h>
#include <limits>
#include <chrono>
#include <algorithm>

// COM
#include <cstdio>
#include <unistd.h>
#include "serial.h"

#include <format_reader_ptr.h>
#include <inference_engine.hpp>
#include <ext_list.hpp>

#include <samples/common.hpp>
#include <samples/slog.hpp>
#include <samples/args_helper.hpp>
#include "object_detection_sample_ssd.h"

#include "opencv2/opencv.hpp"
#include "opencv2/imgproc.hpp"
#include "mv_init.h"

using namespace InferenceEngine;
using namespace cv;

ConsoleErrorListener error_listener;

bool ParseAndCheckCommandLine(int argc, char *argv[]) {
    // ---------------------------Parsing and validation of input args--------------------------------------
    gflags::ParseCommandLineNonHelpFlags(&argc, &argv, true);
    if (FLAGS_h) {
        showUsage();
        return false;
    }

    slog::info << "Parsing input parameters" << slog::endl;

    if (FLAGS_m.empty()) {
        throw std::logic_error("Parameter -m is not set");
    }

    return true;
}

typedef std::chrono::high_resolution_clock Time;
typedef std::chrono::duration<double, std::ratio<1, 1000>> ms;
typedef std::chrono::duration<float> fsec;

/**
* \brief The entry point for the Inference Engine object_detection sample application
* \file object_detection_sample_ssd/main.cpp
* \example object_detection_sample_ssd/main.cpp
*/
int main(int argc, char *argv[]) {
    try {
        /** This sample covers certain topology and cannot be generalized for any object detection one **/
        slog::info << "InferenceEngine: " << GetInferenceEngineVersion() << "\n";

        // --------------------------- 1. Parsing and validation of input args ---------------------------------
        if (!ParseAndCheckCommandLine(argc, argv)) {
            return 0;
        }
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 2. Read input -----------------------------------------------------------
        /** This vector stores paths to the processed images **/

        // --------------------------- 3. Load Plugin for inference engine -------------------------------------
        slog::info << "Loading plugin" << slog::endl;
        InferencePlugin plugin = PluginDispatcher({ FLAGS_pp, "../../../lib/intel64" , "" }).getPluginByDevice(FLAGS_d);
        if (FLAGS_p_msg) {
            static_cast<InferenceEngine::InferenceEnginePluginPtr>(plugin)->SetLogCallback(error_listener);
        }

        /*If CPU device, load default library with extensions that comes with the product*/
        if (FLAGS_d.find("CPU") != std::string::npos) {
            /**
            * cpu_extensions library is compiled from "extension" folder containing
            * custom MKLDNNPlugin layer implementations. These layers are not supported
            * by mkldnn, but they can be useful for inferring custom topologies.
            **/
            plugin.AddExtension(std::make_shared<Extensions::Cpu::CpuExtensions>());
        }

        if (!FLAGS_l.empty()) {
            // CPU(MKLDNN) extensions are loaded as a shared library and passed as a pointer to base extension
            IExtensionPtr extension_ptr = make_so_pointer<IExtension>(FLAGS_l);
            plugin.AddExtension(extension_ptr);
            slog::info << "CPU Extension loaded: " << FLAGS_l << slog::endl;
        }

        if (!FLAGS_c.empty()) {
            // clDNN Extensions are loaded from an .xml description and OpenCL kernel files
            plugin.SetConfig({ { PluginConfigParams::KEY_CONFIG_FILE, FLAGS_c } });
            slog::info << "GPU Extension loaded: " << FLAGS_c << slog::endl;
        }

        /** Setting plugin parameter for per layer metrics **/
        if (FLAGS_pc) {
            plugin.SetConfig({ { PluginConfigParams::KEY_PERF_COUNT, PluginConfigParams::YES } });
        }

        /** Printing plugin version **/
        printPluginVersion(plugin, std::cout);
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 4. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
        std::string binFileName = fileNameNoExt(FLAGS_m) + ".bin";
        slog::info << "Loading network files:"
            "\n\t" << FLAGS_m <<
            "\n\t" << binFileName <<
            slog::endl;

        CNNNetReader networkReader;
        /** Read network model **/
        networkReader.ReadNetwork(FLAGS_m);

        /** Extract model name and load weights **/
        networkReader.ReadWeights(binFileName);
        CNNNetwork network = networkReader.getNetwork();
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 5. Prepare input blobs --------------------------------------------------
        slog::info << "Preparing input blobs" << slog::endl;

        /** Taking information about all topology inputs **/
        InputsDataMap inputsInfo(network.getInputsInfo());

        /** SSD network has one input and one output **/
        if (inputsInfo.size() != 1 && inputsInfo.size() != 2) throw std::logic_error("Sample supports topologies only with 1 or 2 inputs");

        /**
         * Some networks have SSD-like output format (ending with DetectionOutput layer), but
         * having 2 inputs as Faster-RCNN: one for image and one for "image info".
         *
         * Although object_datection_sample_ssd's main task is to support clean SSD, it could score
         * the networks with two inputs as well. For such networks imInfoInputName will contain the "second" input name.
         */
        std::string imageInputName, imInfoInputName;

        InputInfo::Ptr inputInfo = inputsInfo.begin()->second;

        SizeVector inputImageDims;
        /** Stores input image **/

        /** Iterating over all input blobs **/
        for (auto & item : inputsInfo) {
            /** Working with first input tensor that stores image **/
            if (item.second->getInputData()->getTensorDesc().getDims().size() == 4) {
                imageInputName = item.first;

                slog::info << "Batch size is " << std::to_string(networkReader.getNetwork().getBatchSize()) << slog::endl;

                /** Creating first input blob **/
                Precision inputPrecision = Precision::U8;
                item.second->setPrecision(inputPrecision);
            } else if (item.second->getInputData()->getTensorDesc().getDims().size() == 2) {
                imInfoInputName = item.first;

                Precision inputPrecision = Precision::FP32;
                item.second->setPrecision(inputPrecision);
                if ((item.second->getTensorDesc().getDims()[1] != 3 && item.second->getTensorDesc().getDims()[1] != 6) ||
                     item.second->getTensorDesc().getDims()[0] != 1) {
                    throw std::logic_error("Invalid input info. Should be 3 or 6 values length");
                }
            }
        }
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 6. Prepare output blobs -------------------------------------------------
        slog::info << "Preparing output blobs" << slog::endl;

        OutputsDataMap outputsInfo(network.getOutputsInfo());

        std::string outputName;
        DataPtr outputInfo;
        for (const auto& out : outputsInfo) {
            if (out.second->creatorLayer.lock()->type == "DetectionOutput") {
                outputName = out.first;
                outputInfo = out.second;
            }
        }

        if (outputInfo == nullptr) {
            throw std::logic_error("Can't find a DetectionOutput layer in the topology");
        }

        const SizeVector outputDims = outputInfo->getTensorDesc().getDims();

        const int maxProposalCount = outputDims[2];
        const int objectSize = outputDims[3];

        if (objectSize != 7) {
            throw std::logic_error("Output item should have 7 as a last dimension");
        }

        if (outputDims.size() != 4) {
            throw std::logic_error("Incorrect output dimensions for SSD model");
        }

        /** Set the precision of output data provided by the user, should be called before load of the network to the plugin **/
        outputInfo->setPrecision(Precision::FP32);
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 7. Loading model to the plugin ------------------------------------------
        slog::info << "Loading model to the plugin" << slog::endl;

        ExecutableNetwork executable_network = plugin.LoadNetwork(network, {});
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 8. Create infer request -------------------------------------------------
        InferRequest infer_request = executable_network.CreateInferRequest();
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 9. Prepare input --------------------------------------------------------
        /** Collect images data ptrs **/
        std::shared_ptr<unsigned char> imagesData, originalImagesData;
        int imageWidths, imageHeights;
        size_t batchSize = network.getBatchSize();
        slog::info << "Batch size is " << std::to_string(batchSize) << slog::endl;
        if(batchSize != 1)
        {
            slog::warn << "Batch size is " << std::to_string(batchSize) << slog::endl;
        }

        // 相机初始化
		// MvInit camera;
        cv::Mat srcImg;
		
		// 串口初始化
		serial::Serial my_serial(FLAGS_com, 115200, serial::Timeout::simpleTimeout(2));
		if(my_serial.isOpen())
		{
			slog::info << "serial port" << "initialize ok" << slog::endl;
		}else{
			slog::err << "serial port initialize err,please check your COM" << slog::endl;
			return -1;
		}

        // 创建掩膜
        cv::Mat mask = Mat::zeros(Size(RESIZE_IMG_WIDTH,RESIZE_IMG_HEIGHT),CV_8UC1);
        std::vector<std::vector<cv::Point>> contour;
        std::vector<cv::Point> pts;
        pts.push_back(cv::Point(0,79));
        pts.push_back(cv::Point(300,105));
        pts.push_back(cv::Point(300,299));
        pts.push_back(cv::Point(0,299));
        contour.push_back(pts);
        drawContours(mask,contour,0,Scalar::all(255),-1);

		// 创建自适应混合高斯背景建模的背景减除法
		Ptr<BackgroundSubtractorMOG2> bgsubtractor = createBackgroundSubtractorMOG2();
		bgsubtractor->setVarThreshold(10);

		// 读取图像测试
		cv::VideoCapture videoSrc("/home/action/Videos/16_3.avi");

        int still_num = 0;
        int step = 0;
        step = JUDGE_STILL;
        while(1)
        {
            // start time count
            auto t0 = Time::now();
            //srcImg = camera.getImage();
            videoSrc >> srcImg;
            if (srcImg.empty())
            {
                slog::err << "didn't get image" << slog::endl;
                cv::destroyWindow("src");
                return -1;
            }
            cv::imshow("src", srcImg);
            cv::Mat resized(srcImg);
            //if (srcImg.empty()) throw std::logic_error("No suitable images were found");
            cv::resize(srcImg, resized, cv::Size(RESIZE_IMG_WIDTH, RESIZE_IMG_HEIGHT));
            switch(step)
            {
                case JUDGE_STILL:
                {
                    // --------------------------- 6. bsg --------------------------------------------------------
                    cv::Mat grayImg;
                    cv::cvtColor(resized,grayImg,6);
                    // imshow("gray",grayImg);

                    cv::Mat dstImg;
                    grayImg.copyTo(dstImg,mask);
                    // imshow("dst",dstImg);

                    cv::Mat bgmask;
                    bgsubtractor->apply(dstImg,bgmask,0.05);
                    cv::imshow("bmk",bgmask);

                    int redMoreBlueNum = 0;
                    int blueMoreRedNum = 0;
                    // 记录R>B
                    for (int i = 0;i<RESIZE_IMG_HEIGHT;i++)
                    {
                        uchar* bgmaskData = bgmask.ptr<uchar>(i);
                        for(int j = 0;j<RESIZE_IMG_WIDTH;j++)
                        {
                            uchar* srcData = resized.ptr<uchar>(i,j);
                            // 计数需要满足的条件://1、需要为白色，白色的地方说明物体在动。2、R > G(G > R)。3、总体分量比较小，并且需要的分量最大
                            if( (bgmaskData[j]) && (srcData[0] > srcData[2]) && (srcData[0] > srcData[1]) && ((srcData[0] < 100) && (srcData[1] < 70) && (srcData[2] < 70)))
                            {
                                blueMoreRedNum ++;
                            }else if( (bgmaskData[j]) && (srcData[2] > srcData[0]) && (srcData[2] > srcData[1]) && ((srcData[0] < 70) && (srcData[1] < 70) && (srcData[2] < 100)))
                            {
                                redMoreBlueNum ++;
                            }else
                            {
                                continue;
                            }
                        }
                    }

                    if (FLAGS_dg)
                    {
                        cv::imshow("bmk",bgmask);
                    }else{

                    }
                    // std::cout << redMoreBlueNum << " " << blueMoreRedNum << std::endl;
                    if(FLAGS_ch && (redMoreBlueNum < 200))
                    {
                        still_num ++;
                        if(still_num > 2)
                        {
                            step = JUDGE_CLASSES;
                            still_num = 0;
                        }
                    }else if(!FLAGS_ch && (blueMoreRedNum < 200))
                    {
                        still_num ++;
                        if(still_num > 2)
                        {
                            step = JUDGE_CLASSES;
                            still_num = 0;
                        }
                    }else
                    {
                        still_num = 0;
                    }
                    
                }
                break;

                case JUDGE_CLASSES:
                {
                    size_t size = resized.size().width * resized.size().height * resized.channels();
                    imagesData.reset(new unsigned char[size], std::default_delete<unsigned char[]>());

                    // 将图片数据传到imagesData中
                    for (size_t id = 0; id < size; ++id) {
                        imagesData.get()[id] = resized.data[id];
                    }
                    imageWidths = 640;
                    imageHeights = 480;
                    if (imagesData.get() == nullptr)
                    {
                        throw std::logic_error("Valid input images were not found!");
                    }


                    /** Creating input blob **/
                    Blob::Ptr imageInput = infer_request.GetBlob(imageInputName);

                    /** Filling input tensor with images. First b channel, then g and r channels **/
                    size_t num_channels = imageInput->getTensorDesc().getDims()[1];
                    size_t image_size = imageInput->getTensorDesc().getDims()[3] * imageInput->getTensorDesc().getDims()[2];

                    unsigned char* data = static_cast<unsigned char*>(imageInput->buffer());

                    /** Iterate over all input images **/
                    /** Iterate over all pixel in image (b,g,r) **/
                    for (size_t pid = 0; pid < image_size; pid++) {
                        /** Iterate over all channels **/
                        for (size_t ch = 0; ch < num_channels; ++ch) {
                            /**          [images stride + channels stride + pixel id ] all in bytes            **/
                            data[ch * image_size + pid] = imagesData.get()[pid*num_channels + ch];
                        }
                    }
                // --------------------------- 10. Do inference ---------------------------------------------------------
                    infer_request.Infer();
                // --------------------------- 11. Process output -------------------------------------------------------
                    const Blob::Ptr output_blob = infer_request.GetBlob(outputName);
                    const float* detection = static_cast<PrecisionTrait<Precision::FP32>::value_type*>(output_blob->buffer());

                    //std::vector<std::vector<int> > boxes(batchSize);
                    std::vector<std::vector<int> > classes(batchSize);

                    /* Each detection has image_id that denotes processed image */
                    // maxProposalCount is 200
                    // 计算分数
                    int score = 0;
                    for (int curProposal = 0; curProposal < maxProposalCount; curProposal++) {
                        float image_id = detection[curProposal * objectSize + 0];
                        if (image_id < 0) {
                            break;
                        }

                        float label = detection[curProposal * objectSize + 1];
                        float confidence = detection[curProposal * objectSize + 2];
                        float xmin = detection[curProposal * objectSize + 3] * imageWidths;
                        float ymin = detection[curProposal * objectSize + 4] * imageHeights;
                        float xmax = detection[curProposal * objectSize + 5] * imageWidths;
                        float ymax = detection[curProposal * objectSize + 6] * imageHeights;
                        
                        // std::cout << "[" << curProposal << "," << label << "] element, prob = " << confidence <<
                        //     "    (" << xmin << "," << ymin << ")-(" << xmax << "," << ymax << ")" << " batch id : " << image_id;

                        if (confidence > 0.5) {
                            /** Drawing only objects with >50% probability **/
                            // classes[image_id].push_back(static_cast<int>(label));
                            // boxes[image_id].push_back(static_cast<int>(xmin));
                            // boxes[image_id].push_back(static_cast<int>(ymin));
                            // boxes[image_id].push_back(static_cast<int>(xmax - xmin));
                            // boxes[image_id].push_back(static_cast<int>(ymax - ymin));
                            std::cout << label << " WILL BE PRINTED!" << "," << "confidence is:" << confidence << std::endl;;
                            cv::rectangle(srcImg,cv::Rect2f(cv::Point(xmin,ymin),cv::Point(xmax,ymax)),cv::Scalar(255,0,255),1);
                            imshow("objectDecetion",srcImg);
                            // 判断得分
                            switch((int)label)
                            {
                                case 1:
                                    score += 50;
                                break;
                                case 2:
                                    score += 40;
                                break;
                                case 3:
                                    score += 20;
                                break;

                                default:
                                break;
                            }
                        }
                    }
                    std::cout << "score is " << score << std::endl;
                    // draw retangle
                    
                // -----------------------------------------------------------------------------------------------------
                    double total = 0;
                    auto t1 = Time::now();
                    fsec fs = t1 - t0;
                    ms d = std::chrono::duration_cast<ms>(fs);
                    total = d.count();
                    std::cout << "total inference time: " << total << std::endl;
                    std::cout << "Throughput: " << 1000 * static_cast<double>(FLAGS_ni) * batchSize / total << " FPS" << std::endl;
                    std::cout << std::endl;

                    /** Show performance results **/
                    if (FLAGS_pc) {
                        printPerformanceCounts(infer_request, std::cout);
                    }
                    step = JUDGE_STILL;
                }
                break;

                default:
                    step = JUDGE_STILL;
                break;
            }

            // waitKey不是精确延时
            int c = cv::waitKey(30);
            if (c == 'q' || c == 'Q' || (c & 255) == 27)
            {
                //camera.m_bExit = TRUE;
                break;
            }
        }
    }
    catch (const std::exception& error) {
        slog::err << error.what() << slog::endl;
        return 1;
    }
    catch (...) {
        slog::err << "Unknown/internal exception happened." << slog::endl;
        return 1;
    }

    slog::info << "Execution successful" << slog::endl;
    return 0;
}